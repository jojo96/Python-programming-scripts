{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Dataset_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Aw7VmrY5Ytp_",
        "outputId": "656f31f8-66cc-4435-d888-c50468f25010"
      },
      "source": [
        "import keras\r\n",
        "keras.__version__\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwoXvXMZeUa"
      },
      "source": [
        "We'll be working with \"IMDB dataset\", a set of 50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAv63otlZNov",
        "outputId": "b4361192-2131-4103-8d46-8a1d5122287d"
      },
      "source": [
        "from keras.datasets import imdb\r\n",
        "\r\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\r\n",
        "#The argument num_words=10000 means that we will only keep the top 10,000 most frequently occurring words in the training data. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oQecnWEa90u",
        "outputId": "82caadd6-d127-4345-c0ec-6f0fb4eaffef"
      },
      "source": [
        "#The variables train_data and test_data are lists of reviews, each review being a list of word indices (encoding a sequence of words). \r\n",
        "#train_labels and test_labels are lists of 0s and 1s, where 0 stands for \"negative\" and 1 stands for \"positive\":\r\n",
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT3wMJfXbE61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c05e7c-f920-4ecc-d36b-dfc9abc1d449"
      },
      "source": [
        "#Since we restricted ourselves to the top 10,000 most frequent words, no word index will exceed 10,000:\r\n",
        "max([max(sequence) for sequence in train_data])\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brAGwBiNboFx"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def vectorize_sequences(sequences, dimension=10000):\r\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\r\n",
        "    results = np.zeros((len(sequences), dimension))\r\n",
        "    for i, sequence in enumerate(sequences):\r\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\r\n",
        "    return results\r\n",
        "\r\n",
        "# Our vectorized training data\r\n",
        "x_train = vectorize_sequences(train_data)\r\n",
        "# Our vectorized test data\r\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QLSVNjndIaU",
        "outputId": "72ff94c4-7038-438d-facf-fbf443387220"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZMKDPuEdJq0"
      },
      "source": [
        "# Our vectorized labels\r\n",
        "y_train = np.asarray(train_labels).astype('float32')\r\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDDko7CSdNdn"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkMV3rgOdtsb"
      },
      "source": [
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSG5tl5pdvww"
      },
      "source": [
        "\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQtLojKtdxvi"
      },
      "source": [
        "from keras import losses\r\n",
        "from keras import metrics\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aqsik-reVJC"
      },
      "source": [
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk2AiMLBeYqz",
        "outputId": "ebcd0759-c0df-41ea-f0ae-f6dd56813c0f"
      },
      "source": [
        "#training and validation\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.5962 - binary_accuracy: 0.7128 - val_loss: 0.3960 - val_binary_accuracy: 0.8695\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.3362 - binary_accuracy: 0.8948 - val_loss: 0.3069 - val_binary_accuracy: 0.8864\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.2371 - binary_accuracy: 0.9249 - val_loss: 0.3213 - val_binary_accuracy: 0.8663\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1896 - binary_accuracy: 0.9355 - val_loss: 0.2787 - val_binary_accuracy: 0.8869\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1464 - binary_accuracy: 0.9541 - val_loss: 0.2776 - val_binary_accuracy: 0.8887\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.1212 - binary_accuracy: 0.9631 - val_loss: 0.2885 - val_binary_accuracy: 0.8864\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0986 - binary_accuracy: 0.9712 - val_loss: 0.3252 - val_binary_accuracy: 0.8818\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0812 - binary_accuracy: 0.9778 - val_loss: 0.3671 - val_binary_accuracy: 0.8742\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0665 - binary_accuracy: 0.9854 - val_loss: 0.3514 - val_binary_accuracy: 0.8781\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0559 - binary_accuracy: 0.9863 - val_loss: 0.3860 - val_binary_accuracy: 0.8725\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0424 - binary_accuracy: 0.9914 - val_loss: 0.4146 - val_binary_accuracy: 0.8683\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0371 - binary_accuracy: 0.9933 - val_loss: 0.4476 - val_binary_accuracy: 0.8739\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0280 - binary_accuracy: 0.9945 - val_loss: 0.4615 - val_binary_accuracy: 0.8746\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0227 - binary_accuracy: 0.9961 - val_loss: 0.4914 - val_binary_accuracy: 0.8749\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0188 - binary_accuracy: 0.9969 - val_loss: 0.5315 - val_binary_accuracy: 0.8736\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0149 - binary_accuracy: 0.9977 - val_loss: 0.5665 - val_binary_accuracy: 0.8711\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0094 - binary_accuracy: 0.9993 - val_loss: 0.6047 - val_binary_accuracy: 0.8690\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0084 - binary_accuracy: 0.9991 - val_loss: 0.6355 - val_binary_accuracy: 0.8678\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0057 - binary_accuracy: 0.9997 - val_loss: 0.6656 - val_binary_accuracy: 0.8666\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0042 - binary_accuracy: 0.9999 - val_loss: 0.7561 - val_binary_accuracy: 0.8622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8fL6h14edxn",
        "outputId": "50daccfe-37fe-4465-8027-a8932fdbf5ee"
      },
      "source": [
        "history_dict = history.history\r\n",
        "history_dict.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZTTbFNve7kC",
        "outputId": "ae05ac05-8c5f-400c-c9bd-03a31ae54b98"
      },
      "source": [
        "#Let's train a new network from scratch for four epochs, then evaluate it on our test data:\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(32, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 24ms/step - loss: 0.5871 - accuracy: 0.7087\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 23ms/step - loss: 0.2791 - accuracy: 0.9035\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 23ms/step - loss: 0.1904 - accuracy: 0.9335\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 24ms/step - loss: 0.1554 - accuracy: 0.9456\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3439 - accuracy: 0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYtuc2_QfJVQ",
        "outputId": "938ca60e-b8e6-4b09-a337-808fd1cb7e94"
      },
      "source": [
        "results\r\n",
        "\r\n",
        "#Our fairly naive approach achieves an accuracy of 86%."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3438867926597595, 0.8672000169754028]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXm9hO7LgUVq"
      },
      "source": [
        "#SOURCE: https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}